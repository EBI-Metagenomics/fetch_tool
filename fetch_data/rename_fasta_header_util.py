#! /usr/bin/env python
import logging

__author__ = "Hubert DENISE hudenise@ebi.ac.uk (2018)"

import sys
import os
import argparse
import requests
import json


class Utils(object):

    def __init__(self, test):
        self.test = test

    @staticmethod
    def parse_wgs_seq_acc_range(line):
        """
            This method parses the following line:
            scaffolds:FWWM01000001-FWWM01391746
            <assembly-type>:<wgs seq set acc><number>-<wgs seq set acc><number>

            This method parses the WGS sequence set accession, FWWM01 and
            the ordinal number range, 000001-391746

            The line we have to parse is retrieved from an API call.
            The API is maintained by the ENA. Further down below you will find
            an example call and an example response:

            Example call:
            curl -X GET "https://www.ebi.ac.uk/ena/submit/report/analysis-process/ERZ404940?format=json&max-results=100" -H  "accept: */*" -H  "authorization: Basic V2ViaW4tNDI5NzA6M25AIUAyLTEyOA=="

            Example response body (05/10/2018):
            [
              {
                "report": {
                  "id": "ERZ404940",
                  "analysisType": "SEQUENCE_ASSEMBLY",
                  "acc": "scaffolds:FWWM01000001-FWWM01391746",
                  "processingStatus": "COMPLETED",
                  "processingError": null
                },
                "links": []
              }
            ]
        :param amount:
        :return:
        """
        wgs_seq_set_acc, start, end = None, None, None
        if not line:
            logging.warning("Value for line is undefined!")
            return None, None, None
        warn_msg = "Unexpected format of line: {0}".format(line)
        # Split case like  contigs:ODOD01000001-ODOD01010452,contigs(set):ODOD01,genome:GCA_900206415.1
        first_split = line.split(',')[0]
        # Split scaffolds:FWPU01000001-FWPU01204773
        second_split = first_split.split(':')
        if len(second_split) == 2:
            # Split FWPU01000001-FWPU01204773
            third_split = second_split[1].split('-')
            if len(third_split) == 2:
                start = third_split[0][6:]
                end = third_split[1][6:]
                # wgs seq set acc
                wgs_seq_set_acc = third_split[0][:6]
            else:
                logging.warning(warn_msg)
        else:
            logging.warning(warn_msg)
        return wgs_seq_set_acc, int(start), int(end)


def extract_data(study_path, study_id):
    '''
    Function to extract the ERZ_id, GCA identifiers and contig accessions from the study.txt file generated by the fetch_data script
    input: study_path: path to study directory
    input: study_id: ENA study_id
    output: txt_dic: dictionary with ERZ_id as keys and values are list of contig_accessions and GCA identifiers
    '''
    txt_dic = {}
    for line in open(study_path + "/" + study_id + ".txt", "r"):
        line = line.rstrip()
        if line.startswith(study_id):
            elements = line.split("\t")
            txt_dic[elements[14]] = [elements[2], elements[13]]
    return txt_dic


def filter_assemblies(user_list, txt_dic, API_dic):
    '''
    Function to 1) provide translation of contig_name, GCA_id and file_name in ERZ_id, 2) provide biome for each assembly
               and 3) filter the assemblies from the project according to the list optionaly provided by user that could contain any type of identifiers.
    input: user_list: list of assemblies for which the files will be generated (provided as option or all assemblies by default)
    input: txt_dic: dictionary generated by the extract_data function (dic[ERZ_id]:[contig_name, GCA id])
    input: API_dic: dictionary generated by the get_data_from_API function (dic[ERZ_id]:[file_name,scientific_name])
    output: final_dic: dictionary with file_name as key and contig_name as value
    output: biome_dic: dictionary with file_name as key and scientific_name as value
    output: translate_dic: dictionary to translate contig_name, GCA_id and file_name in ERZ_id
    '''
    final_dic = {}
    translate_dic = {}
    biome_dic = {}
    # generating dictionary to translate contig_name, GCA_id and file_name in ERZ_id
    for analysis in txt_dic:
        translate_dic[
            txt_dic[analysis][0]] = analysis  # key: contig_name, value: ERZ_id
        translate_dic[
            txt_dic[analysis][1]] = analysis  # key: GCA_id, value: ERZ_id
        translate_dic[
            API_dic[analysis][0]] = analysis  # key: file_name, value: ERZ_id
        biome_dic[[analysis][0]] = API_dic[analysis][
            1]  # key: file_name, value: scientific_name
    # generating dictionary to translate file_name in contig_name
    for assembly in user_list:
        if assembly in txt_dic:
            final_dic[API_dic[assembly][0]] = txt_dic[assembly][
                0]  # key: file_name, value: contig_name
        elif assembly in translate_dic:
            final_dic[translate_dic[assembly]] = txt_dic[assembly][
                0]  # key: file_name, value: contig_name
    return final_dic, biome_dic, translate_dic


def get_contig_range_from_api(ERZ_id, swagger_url, credentials):
    '''
    Function to get the contig range from the ENA swagger
    input: ERZ_id: individual analysis_id
    output: string corresponding to the names of the first and last contigs separated by hyphen (ex: OFEO01000001-OFEO01173648)
    '''
    # swagger query
    url = swagger_url + ERZ_id + '?'
    payload = {"format": "json"}
    headers = {"Accept": "*/*"}
    try:
        res = requests.get(
            url,
            headers=headers,
            data=payload,
            auth=credentials
        )
    except:
        raise
    swaggerData = res.json()
    # first element of swagger query: dictionary
    entry = swaggerData[0]
    # get the 'report' value which is a dictionary itself and extract the 'acc' value then remove strings before and after contig range
    data_contig = entry['report']['acc'].split(",")[0]
    return data_contig


def get_scientific_name(analysis_accession, api_url, credentials,
                        dcc_data_only=False):
    '''
    Function to get analysis_accession (ERZ_id), analysis_alias (file_name) and scientific_name for all assemblies of a project
    input: study_id
    input: dictionary generated by the extract_data function (dic[ERZ_id]:[contig_name, GCA id])
    input API_URL: url for the ENA API
    output: api_dic: dictionary with ERZ_id as keys and values are list of file_name and scientific_name
    '''
    query_string = 'analysis_accession="{0}"'.format(analysis_accession)
    payload = {
        "result": "analysis",
        "query": query_string,
        "fields": "analysis_accession,scientific_name",
        "dataPortal": "metagenome",
        "format": "json",
    }
    if dcc_data_only:
        payload['dccDataOnly'] = True
    headers = {'content-type': 'application/x-www-form-urlencoded'}
    try:
        res = requests.post(
            api_url,
            headers=headers,
            data=payload,
            auth=credentials  # of type tuple
        )
    except:
        raise
    results = res.json()
    if len(results) == 0:
        logging.error("No results received for analysis object: {0}".format(
            analysis_accession))
        logging.error("Shutting down the program now!")
        sys.exit(1)
    elif len(results) > 1:
        logging.error(
            "Unexpected number of results received for analysis object: {0}".format(
                analysis_accession))
        logging.error("Shutting down the program now!")
        sys.exit(1)
    else:
        scientific_name = results[0]['scientific_name']
        return scientific_name


def write_assembly(input_file_path, analysis_id, output_file_path,
                   scientific_name, s_url, s_credentials):
    """

    :param input_file_path: Path to the uncompressed user submitted FASTA file
    :param analysis_id: ENA's analysis accession, e.g. ERZ000001
    :param output_file_path: raw file output folder
    :param scientific_name: ENA's scientific_name name for the given analysis
            accession, e.g. marine metagenome
    :param s_url:
    :param s_credentials:
    :return:
    """
    range = get_contig_range_from_api(analysis_id, s_url, s_credentials)
    wgs_seq_set_acc, first_contig_number, last_contig_number = \
        Utils.parse_wgs_seq_acc_range(range)
    # get first and last contig names. This will allow to avoid contigs the contigs as number of '0' in contig name depends on number of contigs
    counter = 0

    with open(output_file_path, "w") as new_file, \
            open(input_file_path, "r") as old_file:
        for line in old_file:
            if line.startswith(">"):
                space_index = line.find(' ')
                config_name = line[1:space_index]
                seq_ordinal_num = first_contig_number + counter
                fill = 6
                if seq_ordinal_num > 999999:
                    fill = 7
                elif seq_ordinal_num > 9999999:
                    fill = 8
                seq_ordinal_num_str = "{pk:0>{fill}}".format(
                    pk=seq_ordinal_num, fill=fill)
                newline = ''.join(
                    ['>ENA|', wgs_seq_set_acc, seq_ordinal_num_str,
                     '|', wgs_seq_set_acc, seq_ordinal_num_str,
                     '.1 ', scientific_name,
                     " genome assembly, contig: ", config_name, "\n"])
                new_file.write(newline)
                counter += 1
            else:
                new_file.write(line)


def rename_raw_file(source, destination):
    os.rename(source, destination)


def change_fasta_headers(input_file_path, output_file_path,
                         analysis_id, swagger_url, swagger_credentials,
                         api_url, api_credentials):
    scientific_name = get_scientific_name(analysis_id, api_url,
                                          api_credentials)
    write_assembly(input_file_path, analysis_id, output_file_path,
                   scientific_name, swagger_url, swagger_credentials)


def main():
    parser = argparse.ArgumentParser(
        description="Rename_private_assemblies.py: script to rename submitted private assemblies to format identical to ENA-generated contig files.\nCommand: Rename_private_assemblies.py -p <study_id> -i <path to to directory where study data were downloaded> <option: -d <path to destination directory> -l <list of assemblies of interest, separated by comma>")
    parser.add_argument("-p", "--project", help="Project accession",
                        dest="project_acc",
                        required=True)
    parser.add_argument("-i", "--input",
                        help="Path to directory where the study folder is (created by the fetch_script)",
                        dest="inputpath", required=True)
    parser.add_argument("-d", "--outputDirectory",
                        help="Output directory where the run result directory will be created. If not indicated: input folder will be used",
                        dest="outputpath", required=False)
    parser.add_argument("-l", "--assemblyList",
                        help="list of assemblies of interest (ERZ or GCA or S/E/DRR or contig",
                        dest="assemblylist", required=False)
    parser.add_argument("-c", "--config",
                        help="Path to config file (not sure if required)",
                        dest="config",
                        default="rename_fasta_header_util-config-prod.json")
    args = parser.parse_args()

    logging.basicConfig(format='%(levelname)s %(asctime)s - %(message)s',
                        datefmt='%Y/%m/%d %I:%M:%S %p',
                        level=logging.DEBUG)

    # get arguments from config file
    config_file_path = args.config
    with open(config_file_path, "r") as config_file:
        configSettings = json.load(config_file)
        API_URL = configSettings['API_URL']
        API_credentials = (
            str(configSettings['API_login']),
            str(configSettings['API_pssword']))
    swagger_URL = configSettings['swagger_URL']
    swagger_credentials = (
        str(configSettings['swagger_login']),
        str(configSettings['swagger_pssword']))
    # validate arguments
    # study_id
    if len(args.project_acc) == 9 and "RP" in args.project_acc:
        study_id = args.project_acc
    else:
        print("The study_id indicated is not valid. Exiting now")
        sys.exit()
    # input path
    if args.inputpath.endswith("/"):
        inpath = args.inputpath[:-1]
    else:
        inpath = args.inputpath
    input_folder = os.path.join(inpath, study_id)
    input_file_path = os.path.join(input_folder, study_id + ".txt")
    if not os.path.exists(input_file_path):
        print(
            "Could not find input file at\n" + input_file_path +
            "\nProgram will exit now!")
        sys.exit()
    # output path
    if args.outputpath:
        outpath = args.outputpath
        if not args.outputpath.endswith("/"):
            outpath = args.outputpath + "/"
        if not os.path.isdir(outpath + study_id):
            os.mkdir(outpath + study_id)
        if not os.path.isdir(outpath + study_id + "/raw"):
            os.mkdir(outpath + study_id + "/raw")
        outpath = outpath + study_id + "/raw"
    else:
        outpath = input_folder + "/raw"
    # open the study.txt and extract information of interest
    analysis_txt_dic = extract_data(input_folder, study_id)
    # assembly_list
    if args.assemblylist:
        working_list = args.assemblylist.split(",")
    else:
        working_list = analysis_txt_dic.keys()
    # get contig prefix and scientific_name from ENA API
    analyis_API_dic = get_scientific_name(study_id, analysis_txt_dic, API_URL,
                                          API_credentials)
    # get contig range from ENA swagger and filter assemblies if user provided a list of assemblies
    resulting_dic, biome_dic, translation_dic = filter_assemblies(working_list,
                                                                  analysis_txt_dic,
                                                                  analyis_API_dic)
    # generate new files and add sequences with correct names
    write_assembly(input_folder, outpath, resulting_dic, biome_dic,
                   translation_dic, swagger_URL, swagger_credentials)


if __name__ == '__main__':
    main()
